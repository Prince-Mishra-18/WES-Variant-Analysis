{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ms_8u4OK0A1n",
        "outputId": "0694ed12-7a28-42c0-b8bb-e8474b1a0373"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "wget is already the newest version (1.21.2-2ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "/content/annovar\n",
            "--2025-08-07 15:43:29--  http://www.openbioinformatics.org/annovar/download/0wgxR2rIVP/annovar.latest.tar.gz\n",
            "Resolving www.openbioinformatics.org (www.openbioinformatics.org)... 67.205.156.247\n",
            "Connecting to www.openbioinformatics.org (www.openbioinformatics.org)|67.205.156.247|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 280727629 (268M) [application/x-gzip]\n",
            "Saving to: ‘annovar.latest.tar.gz’\n",
            "\n",
            "annovar.latest.tar. 100%[===================>] 267.72M  88.2MB/s    in 3.0s    \n",
            "\n",
            "2025-08-07 15:43:32 (88.2 MB/s) - ‘annovar.latest.tar.gz’ saved [280727629/280727629]\n",
            "\n",
            "annovar/\n",
            "annovar/example/\n",
            "annovar/example/ex1.avinput\n",
            "annovar/example/example.simple_region\n",
            "annovar/example/example.tab_region\n",
            "annovar/example/ex2.vcf\n",
            "annovar/example/grantham.matrix\n",
            "annovar/example/snplist.txt\n",
            "annovar/example/README\n",
            "annovar/example/gene_xref.txt\n",
            "annovar/example/gene_fullxref.txt\n",
            "annovar/humandb/\n",
            "annovar/humandb/hg19_refGene.txt\n",
            "annovar/humandb/hg19_refGeneMrna.fa\n",
            "annovar/humandb/hg19_refGeneVersion.txt\n",
            "annovar/humandb/hg19_refGeneWithVer.txt\n",
            "annovar/humandb/hg19_refGeneWithVerMrna.fa\n",
            "annovar/humandb/hg38_ensGeneMrna.fa\n",
            "annovar/humandb/hg38_ensGene.txt\n",
            "annovar/humandb/hg38_refGeneWithVer.txt\n",
            "annovar/humandb/hg38_refGeneWithVerMrna.fa\n",
            "annovar/humandb/hg19_example_db_generic.txt\n",
            "annovar/humandb/hg19_example_db_gff3.txt\n",
            "annovar/humandb/GRCh37_MT_ensGene.txt\n",
            "annovar/humandb/GRCh37_MT_ensGeneMrna.fa\n",
            "annovar/humandb/hg19_MT_ensGene.txt\n",
            "annovar/humandb/hg19_MT_ensGeneMrna.fa\n",
            "annovar/humandb/genometrax-sample-files-gff/\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_mirna_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_microsatellites_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_hgmd_disease_genes_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_evs_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_pathway_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_tcga_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_vista_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_cpg_islands_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_transfac_sites_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_dbnsfp_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_omim_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/list\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_dnase_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_hgmd_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_dbscsnv_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_clinvar_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_fulldbsnp_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_complete_genomics_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_tss_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_ptms_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_orpha_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_ethnicsnp_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_chip_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_drug_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_hgmdimputed_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_pgmd_featuretype_hg38.gff\n",
            "annovar/annotate_variation.pl\n",
            "annovar/table_annovar.pl\n",
            "annovar/convert2annovar.pl\n",
            "annovar/retrieve_seq_from_fasta.pl\n",
            "annovar/coding_change.pl\n",
            "annovar/variants_reduction.pl\n"
          ]
        }
      ],
      "source": [
        "# Install wget if needed\n",
        "!apt-get install wget -y\n",
        "\n",
        "# Create a working directory\n",
        "!mkdir -p /content/annovar\n",
        "\n",
        "# Move into that directory\n",
        "%cd /content/annovar\n",
        "\n",
        "# Download ANNOVAR using your personal link (replace with your own if needed)\n",
        "!wget http://www.openbioinformatics.org/annovar/download/0wgxR2rIVP/annovar.latest.tar.gz\n",
        "\n",
        "# Extract it\n",
        "!tar -zxvf annovar.latest.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!perl annovar/annotate_variation.pl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbz2H-hx0lTY",
        "outputId": "caffbd64-801c-4cbb-eb25-5a46222bcf3c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usage:\n",
            "     annotate_variation.pl [arguments] <query-file|table-name> <database-location>\n",
            "\n",
            "     Optional arguments:\n",
            "            -h, --help                      print help message\n",
            "            -m, --man                       print complete documentation\n",
            "            -v, --verbose                   use verbose output\n",
            "        \n",
            "            Arguments to download databases or perform annotations\n",
            "                --downdb                    download annotation database\n",
            "                --geneanno                  annotate variants by gene-based annotation (infer functional consequence on genes)\n",
            "                --regionanno                annotate variants by region-based annotation (find overlapped regions in database)\n",
            "                --filter                    annotate variants by filter-based annotation (find identical variants in database)\n",
            "        \n",
            "            Arguments to control input and output\n",
            "                --outfile <file>            output file prefix\n",
            "                --webfrom <string>          specify the source of database (ucsc or annovar or URL) (downdb operation)\n",
            "                --dbtype <string>           specify database type\n",
            "                --buildver <string>         specify genome build version (default: hg18 for human)\n",
            "                --time                      print out local time during program run\n",
            "                --comment                   print out comment line (those starting with #) in output files \n",
            "                --exonsort                  sort the exon number in output line (gene-based annotation)\n",
            "                --transcript_function       use transcript name rather than gene name (gene-based annotation)\n",
            "                --hgvs                      use HGVS format for exonic annotation (c.122C>T rather than c.C122T) (gene-based annotation)\n",
            "                --separate                  separately print out all functions of a variant in several lines (gene-based annotation)\n",
            "                --seq_padding               create a new file with cDNA sequence padded by this much either side (gene-based annotation)\n",
            "                --(no)firstcodondel         treat first codon deletion as wholegene deletion (default: ON) (gene-based annotation)\n",
            "                --aamatrix <file>           specify an amino acid substitution matrix file (gene-based annotation)\n",
            "                --colsWanted <string>       specify which columns to output by comma-delimited numbers (region-based annotation)\n",
            "                --scorecolumn <int>         the column with scores in DB file (region-based annotation)\n",
            "                --poscolumn <string>        the comma-delimited column with position information in DB file (region-based annotation)\n",
            "                --gff3dbfile <file>         specify a DB file in GFF3 format (region-based annotation)\n",
            "                --gff3attribute             output all fields in GFF3 attribute (default: ID and score only)\n",
            "                --bedfile <file>            specify a DB file in BED format file (region-based annotation)\n",
            "                --genericdbfile <file>      specify a DB file in generic format (filter-based annotation)\n",
            "                --vcfdbfile <file>          specify a DB file in VCF format (filter-based annotation)\n",
            "                --otherinfo                 print out additional columns in database file (filter-based annotation)\n",
            "                --infoasscore               use INFO field in VCF file as score in output (filter-based annotation)\n",
            "                --idasscore                 use ID field in VCF file as score in output (filter-based annotation)\n",
            "                --infosep                   use # rather than , to separate fields when -otherinfo is used\n",
            "\n",
            "        \n",
            "            Arguments to fine-tune the annotation procedure\n",
            "                --batchsize <int>           batch size for processing variants per batch (default: 5m)\n",
            "                --genomebinsize <int>       bin size to speed up search (default: 100k for -geneanno, 10k for -regionanno)\n",
            "                --expandbin <int>           check nearby bin to find neighboring genes (default: 2m/genomebinsize)\n",
            "                --neargene <int>            distance threshold to define upstream/downstream of a gene\n",
            "                --exonicsplicing            report exonic variants near exon/intron boundary as 'exonic;splicing' variants\n",
            "                --score_threshold <float>   minimum score of DB regions to use in annotation\n",
            "                --normscore_threshold <float> minimum normalized score of DB regions to use in annotation\n",
            "                --reverse                   reverse directionality to compare to score_threshold\n",
            "                --rawscore                  output includes the raw score (not normalized score) in UCSC Browser Track\n",
            "                --minqueryfrac <float>      minimum percentage of query overlap to define match to DB (default: 0)\n",
            "                --splicing_threshold <int>  distance between splicing variants and exon/intron boundary (default: 2)\n",
            "                --indel_splicing_threshold <int>    if set, use this value for allowed indel size for splicing variants (default: --splicing_threshold)\n",
            "                --maf_threshold <float>     filter 1000G variants with MAF above this threshold (default: 0)\n",
            "                --sift_threshold <float>    SIFT threshold for deleterious prediction for -dbtype avsift (default: 0.05)\n",
            "                --precedence <string>       comma-delimited to specify precedence of variant function (default: exonic>intronic...)\n",
            "                --indexfilter_threshold <float>     controls whether filter-based annotation use index if this fraction of bins need to be scanned (default: 0.9)\n",
            "                --thread <int>              use multiple threads for filter-based annotation\n",
            "                --maxgenethread <int>       max number of threads for gene-based annotation (default: 6)\n",
            "                --mingenelinecount <int>    min line counts to enable threaded gene-based annotation (default: 1000000)\n",
            "       \n",
            "           Arguments to control memory usage\n",
            "                --memfree <int>             ensure minimum amount of free system memory (default: 0)\n",
            "                --memtotal <int>            limit total amount of memory used by ANNOVAR (default: 0, unlimited, in the order of kb)\n",
            "                --chromosome <string>       examine these specific chromosomes in database file\n",
            "            \n",
            "\n",
            "     Function: annotate a list of genetic variants against genome annotation \n",
            "     databases stored at local disk.\n",
            "\n",
            "     Important Note: please note that the recommended way to use annotate_variation.pl is through table_annovar.pl which handles some extra issues such as polishing the amino acid changes and also adding HGVS nomenclature to intronic variants.\n",
            " \n",
            "     Example: #download annotation databases from ANNOVAR or UCSC and save to humandb/ directory\n",
            "              annotate_variation.pl -downdb -webfrom annovar refGene humandb/\n",
            "              annotate_variation.pl -downdb -buildver mm9 refGene mousedb/\n",
            "              annotate_variation.pl -downdb -buildver hg19 -webfrom annovar esp6500siv2_all humandb/\n",
            "        \n",
            "              #gene-based annotation of variants in the varlist file (by default --geneanno is ON)\n",
            "              annotate_variation.pl -geneanno -buildver hg19 ex1.avinput humandb/\n",
            "          \n",
            "              #region-based annotate variants\n",
            "              annotate_variation.pl -regionanno -buildver hg19 -dbtype cytoBand ex1.avinput humandb/\n",
            "              annotate_variation.pl -regionanno -buildver hg19 -dbtype gff3 -gff3dbfile tfbs.gff3 ex1.avinput humandb/\n",
            "          \n",
            "              #filter rare or unreported variants (in 1000G/dbSNP) or predicted deleterious variants\n",
            "              annotate_variation.pl -filter -dbtype 1000g2015aug_all -maf 0.01 ex1.avinput humandb/\n",
            "              annotate_variation.pl -filter -buildver hg19 -dbtype snp138 ex1.avinput humandb/\n",
            "              annotate_variation.pl -filter -dbtype dbnsfp35a -buildver hg38 ex1.avinput humandb/\n",
            "              annotate_variation.pl -filter -dbtype gnomad211_exome -buildver hg19 ex1.avinput humandb/\n",
            " \n",
            "     Version: $Date: 2025-03-02 22:37:01 -0500 (Sun,  2 Mar 2025) $\n",
            "\n",
            "     Important Note Again: please note that the recommended way to use annotate_variation.pl is through table_annovar.pl which handles some extra issues such as polishing the amino acid changes and also adding HGVS nomenclature to intronic variants.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "aAI0a2SrPPyE",
        "outputId": "40c77ad6-f77d-4135-c507-bbc24b39d89c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-65953e2b-37cc-44b4-88b5-2343d00b4033\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-65953e2b-37cc-44b4-88b5-2343d00b4033\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving SRR766039_raw.csv to SRR766039_raw.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the file after upload\n",
        "df = pd.read_csv(\"SRR766039_raw.csv\")\n",
        "\n",
        "# Rename column for consistency\n",
        "df.rename(columns={\"#CHROM\": \"CHROM\"}, inplace=True)\n",
        "\n",
        "# Create START and END columns\n",
        "df[\"START\"] = df[\"POS\"]\n",
        "df[\"END\"] = df[\"POS\"]\n",
        "\n",
        "# Select and reorder columns for AVinput format\n",
        "avinput_df = df[[\"CHROM\", \"START\", \"END\", \"REF\", \"ALT\"]]\n",
        "\n",
        "# Save as AVinput file (no headers or index)\n",
        "avinput_df.to_csv(\"input.avinput\", sep=\"\\t\", index=False, header=False)\n",
        "\n",
        "print(\"✅ AVinput file 'input.avinput' created successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uqL-qfd0t36",
        "outputId": "8976c095-606a-40c2-e3d5-25a5e862df90"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ AVinput file 'input.avinput' created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('input.avinput')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "xM1C9h6V1hx5",
        "outputId": "241bada2-3f16-4084-eecf-f5d2556e3510"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4820e574-257d-40e7-86f5-d01c5d5862b3\", \"input.avinput\", 16936523)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd annovar/\n"
      ],
      "metadata": {
        "id": "hlnIHDIB2_m1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c64656d-dd1c-472a-a18d-cd7512641f5b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/annovar/annovar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!perl annotate_variation.pl -buildver hg38 -downdb -webfrom annovar refGene humandb/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nm97ar9O3rRe",
        "outputId": "af3c17c1-0f1b-444d-af28-4e84b3000002"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTICE: Web-based checking to see whether ANNOVAR new version is available ... Done\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg38_refGene.txt.gz ... OK\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg38_refGeneMrna.fa.gz ... OK\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg38_refGeneVersion.txt.gz ... OK\n",
            "NOTICE: Uncompressing downloaded files\n",
            "NOTICE: Finished downloading annotation files for hg38 build version, with files saved at the 'humandb' directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ClinVar annotations (disease relevance)\n",
        "!perl annotate_variation.pl -buildver hg38 -downdb -webfrom annovar clinvar_20220320 humandb/\n",
        "\n",
        "# dbNSFP (functional predictions like SIFT, PolyPhen)\n",
        "!perl annotate_variation.pl -buildver hg38 -downdb -webfrom annovar dbnsfp42a humandb/\n",
        "\n",
        "# gnomAD population allele frequency\n",
        "!perl annotate_variation.pl -buildver hg38 -downdb -webfrom annovar gnomad211_genome humandb/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3949RCcz3uLr",
        "outputId": "f963ee0b-93ab-4be7-f249-e4972ccb0177"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTICE: Web-based checking to see whether ANNOVAR new version is available ... Done\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg38_clinvar_20220320.txt.gz ... OK\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg38_clinvar_20220320.txt.idx.gz ... OK\n",
            "NOTICE: Uncompressing downloaded files\n",
            "NOTICE: Finished downloading annotation files for hg38 build version, with files saved at the 'humandb' directory\n",
            "NOTICE: Web-based checking to see whether ANNOVAR new version is available ... Done\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg38_dbnsfp42a.txt.gz ... OK\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg38_dbnsfp42a.txt.idx.gz ... OK\n",
            "NOTICE: Uncompressing downloaded files\n",
            "NOTICE: Finished downloading annotation files for hg38 build version, with files saved at the 'humandb' directory\n",
            "NOTICE: Web-based checking to see whether ANNOVAR new version is available ... Done\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg38_gnomad211_genome.txt.gz ... OK\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg38_gnomad211_genome.txt.idx.gz ... OK\n",
            "NOTICE: Uncompressing downloaded files\n",
            "\n",
            "gzip: hg38_gnomad211_genome.txt: No space left on device\n",
            "\n",
            "ERROR: the downloaded file hg38_gnomad211_genome.txt.gz cannot be unzipped successfully, possibly due to corrupted file. Please try -downdb again\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./annotate_variation.pl -downdb -webfrom annovar gnomad211_exome humandb/ -buildver hg38\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3819daOIUw60",
        "outputId": "2af9a572-9209-469d-d8f3-5ba02187fd12"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTICE: Web-based checking to see whether ANNOVAR new version is available ... Done\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg38_gnomad211_exome.txt.gz ... OK\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg38_gnomad211_exome.txt.idx.gz ... OK\n",
            "NOTICE: Uncompressing downloaded files\n",
            "NOTICE: Finished downloading annotation files for hg38 build version, with files saved at the 'humandb' directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/\n",
        "!wget http://www.openbioinformatics.org/annovar/download/annovar.latest.tar.gz\n",
        "!tar -zxvf annovar.latest.tar.gz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsfes7QpWe9A",
        "outputId": "f20d8491-0a5c-4ed3-9dfe-efe761120f31"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-07 16:26:10--  http://www.openbioinformatics.org/annovar/download/annovar.latest.tar.gz\n",
            "Resolving www.openbioinformatics.org (www.openbioinformatics.org)... 67.205.156.247\n",
            "Connecting to www.openbioinformatics.org (www.openbioinformatics.org)|67.205.156.247|:80... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-08-07 16:26:10 ERROR 404: Not Found.\n",
            "\n",
            "annovar/\n",
            "annovar/example/\n",
            "annovar/example/ex1.avinput\n",
            "annovar/example/example.simple_region\n",
            "annovar/example/example.tab_region\n",
            "annovar/example/ex2.vcf\n",
            "annovar/example/grantham.matrix\n",
            "annovar/example/snplist.txt\n",
            "annovar/example/README\n",
            "annovar/example/gene_xref.txt\n",
            "annovar/example/gene_fullxref.txt\n",
            "annovar/humandb/\n",
            "annovar/humandb/hg19_refGene.txt\n",
            "annovar/humandb/hg19_refGeneMrna.fa\n",
            "annovar/humandb/hg19_refGeneVersion.txt\n",
            "annovar/humandb/hg19_refGeneWithVer.txt\n",
            "annovar/humandb/hg19_refGeneWithVerMrna.fa\n",
            "annovar/humandb/hg38_ensGeneMrna.fa\n",
            "annovar/humandb/hg38_ensGene.txt\n",
            "annovar/humandb/hg38_refGeneWithVer.txt\n",
            "annovar/humandb/hg38_refGeneWithVerMrna.fa\n",
            "annovar/humandb/hg19_example_db_generic.txt\n",
            "annovar/humandb/hg19_example_db_gff3.txt\n",
            "annovar/humandb/GRCh37_MT_ensGene.txt\n",
            "annovar/humandb/GRCh37_MT_ensGeneMrna.fa\n",
            "annovar/humandb/hg19_MT_ensGene.txt\n",
            "annovar/humandb/hg19_MT_ensGeneMrna.fa\n",
            "annovar/humandb/genometrax-sample-files-gff/\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_mirna_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_microsatellites_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_hgmd_disease_genes_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_evs_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_pathway_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_tcga_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_vista_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_cpg_islands_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_transfac_sites_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_dbnsfp_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_omim_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/list\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_dnase_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_hgmd_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_dbscsnv_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_clinvar_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_fulldbsnp_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_complete_genomics_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_tss_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_ptms_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_orpha_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_ethnicsnp_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_chip_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_drug_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_hgmdimputed_featuretype_hg38.gff\n",
            "annovar/humandb/genometrax-sample-files-gff/sample_pgmd_featuretype_hg38.gff\n",
            "annovar/annotate_variation.pl\n",
            "annovar/table_annovar.pl\n",
            "annovar/convert2annovar.pl\n",
            "annovar/retrieve_seq_from_fasta.pl\n",
            "annovar/coding_change.pl\n",
            "annovar/variants_reduction.pl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!perl /content/annovar/annovar/annotate_variation.pl -buildver hg38 -downdb -webfrom annovar refGene /content/annovar/humandb/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHg61DZ2Xsgm",
        "outputId": "ac6e1b04-b9fb-4e6d-a3b5-ad5eab5d40df"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTICE: Web-based checking to see whether ANNOVAR new version is available ... Done\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg38_refGene.txt.gz ... OK\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg38_refGeneMrna.fa.gz ... OK\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg38_refGeneVersion.txt.gz ... OK\n",
            "NOTICE: Uncompressing downloaded files\n",
            "NOTICE: Finished downloading annotation files for hg38 build version, with files saved at the '/content/annovar/humandb' directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!perl /content/annovar/annovar/annotate_variation.pl -buildver hg38 -downdb -webfrom annovar gnomad211_exome /content/annovar/humandb/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeJqgA3DX1kb",
        "outputId": "b4de0c85-6dc0-40b2-ff1f-da63af2ecb6b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTICE: Web-based checking to see whether ANNOVAR new version is available ... Done\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg38_gnomad211_exome.txt.gz ... OK\n",
            "NOTICE: Downloading annotation database http://www.openbioinformatics.org/annovar/download/hg38_gnomad211_exome.txt.idx.gz ... OK\n",
            "NOTICE: Uncompressing downloaded files\n",
            "NOTICE: Finished downloading annotation files for hg38 build version, with files saved at the '/content/annovar/humandb' directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!perl /content/annovar/annovar/table_annovar.pl \\\n",
        "/content/annovar/SRR766039.avinput \\\n",
        "/content/annovar/humandb/ \\\n",
        "-buildver hg38 \\\n",
        "-out /content/annovar/SRR766039_output \\\n",
        "-remove \\\n",
        "-protocol refGene,gnomad211_exome \\\n",
        "-operation g,f \\\n",
        "-nastring . \\\n",
        "-polish \\\n",
        "-otherinfo\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TG0raBmzVH9k",
        "outputId": "c5e0f3be-4ea2-4465-d195-1b1ac367d73c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------\n",
            "NOTICE: Processing operation=g protocol=refGene\n",
            "\n",
            "NOTICE: Running with system command <annotate_variation.pl -geneanno -buildver hg38 -dbtype refGene -outfile /content/annovar/SRR766039_output.refGene -exonsort -nofirstcodondel /content/annovar/SRR766039.avinput /content/annovar/humandb/>\n",
            "NOTICE: Output files are written to /content/annovar/SRR766039_output.refGene.variant_function, /content/annovar/SRR766039_output.refGene.exonic_variant_function\n",
            "NOTICE: Reading gene annotation from /content/annovar/humandb/hg38_refGene.txt ... Done with 88819 transcripts (including 21511 without coding sequence annotation) for 28307 unique genes\n",
            "NOTICE: Processing next batch with 565791 unique variants in 565791 input lines\n",
            "NOTICE: Reading FASTA sequences from /content/annovar/humandb/hg38_refGeneMrna.fa ... Done with 26643 sequences\n",
            "WARNING: A total of 606 sequences will be ignored due to lack of correct ORF annotation\n",
            "NOTICE: Variants with invalid input format are written to /content/annovar/SRR766039_output.refGene.invalid_input\n",
            "\n",
            "NOTICE: Running with system command <coding_change.pl  /content/annovar/SRR766039_output.refGene.exonic_variant_function.orig /content/annovar/humandb//hg38_refGene.txt /content/annovar/humandb//hg38_refGeneMrna.fa -alltranscript -out /content/annovar/SRR766039_output.refGene.fa -newevf /content/annovar/SRR766039_output.refGene.exonic_variant_function>\n",
            "-----------------------------------------------------------------\n",
            "NOTICE: Processing operation=f protocol=gnomad211_exome\n",
            "NOTICE: Finished reading 17 column headers for '-dbtype gnomad211_exome'\n",
            "\n",
            "NOTICE: Running system command <annotate_variation.pl -filter -dbtype gnomad211_exome -buildver hg38 -outfile /content/annovar/SRR766039_output /content/annovar/SRR766039.avinput /content/annovar/humandb/ -otherinfo>\n",
            "NOTICE: Output file with variants matching filtering criteria is written to /content/annovar/SRR766039_output.hg38_gnomad211_exome_dropped, and output file with other variants is written to /content/annovar/SRR766039_output.hg38_gnomad211_exome_filtered\n",
            "NOTICE: Processing next batch with 565791 unique variants in 587638 input lines\n",
            "NOTICE: Database index loaded. Total number of bins is 771804 and the number of bins to be scanned is 56219\n",
            "NOTICE: Scanning filter database /content/annovar/humandb/hg38_gnomad211_exome.txt...Done\n",
            "NOTICE: Variants with invalid input format are written to /content/annovar/SRR766039_output.invalid_input\n",
            "-----------------------------------------------------------------\n",
            "NOTICE: Multianno output file is written to /content/annovar/SRR766039_output.hg38_multianno.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the annotated file\n",
        "df = pd.read_csv(\"/content/annovar/SRR766039_output.hg38_multianno.txt\", sep='\\t')\n",
        "\n",
        "# Save as CSV\n",
        "df.to_csv(\"/content/annovar/SRR766039_output.hg38_multianno.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "AnM2tFXZYhwj"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/annovar/SRR766039_output.hg38_multianno.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Fvpxe1J6YofF",
        "outputId": "d5bea454-a043-428d-c087-289af0fde0f3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_92d919a3-c995-4377-8f68-ff9a53919bfb\", \"SRR766039_output.hg38_multianno.csv\", 65534361)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "last line\n"
      ],
      "metadata": {
        "id": "9Njmzxi0VNkA"
      }
    }
  ]
}